import os
import sys
import ssl
import time
import json
import re
import random
from datetime import datetime
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor

# --- 1. KURULUMLAR ---
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

if sys.version_info >= (3, 12):
    try:
        import setuptools
        from setuptools import _distutils
        sys.modules["distutils"] = _distutils
    except ImportError:
        pass

import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# --- AYARLAR ---
BASE_URL = "https://www.maximum.com.tr"
CAMPAIGNS_URL = "https://www.maximum.com.tr/kampanyalar"
OUTPUT_FILE = "maximum_kampanyalar_final_v7.json"
IMPORT_SOURCE_NAME = "Maximum Kart"
CAMPAIGN_LIMIT = 1000 

# --- YARDIMCI FONKSƒ∞YONLAR ---
def tr_lower(text):
    return text.replace('I', 'ƒ±').replace('ƒ∞', 'i').lower() if text else ""

def temizle_metin(text):
    if not text: return ""
    text = text.replace('\n', ' ').replace('\r', '')
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def format_rakam(rakam_int):
    try: return f"{int(rakam_int):,}".replace(",", ".")
    except: return None

def format_tarih_iso(tarih_str, is_end=False):
    if not tarih_str: return None
    ts = tr_lower(tarih_str)
    aylar = {'ocak':'01','≈üubat':'02','mart':'03','nisan':'04','mayƒ±s':'05','haziran':'06',
             'temmuz':'07','aƒüustos':'08','eyl√ºl':'09','ekim':'10','kasƒ±m':'11','aralƒ±k':'12'}
    try:
        m_dot = re.search(r'(\d{1,2})\.(\d{1,2})\.(\d{4})\s*-\s*(\d{1,2})\.(\d{1,2})\.(\d{4})', ts)
        if m_dot:
            g1, a1, y1, g2, a2, y2 = m_dot.groups()
            if is_end: return f"{y2}-{a2.zfill(2)}-{g2.zfill(2)}T23:59:59Z"
            else: return f"{y1}-{a1.zfill(2)}-{g1.zfill(2)}T00:00:00Z"
        
        m = re.search(r'(\d{1,2})\s*([a-zƒü√º≈üƒ±√∂√ß]+)?\s*-\s*(\d{1,2})\s*([a-zƒü√º≈üƒ±√∂√ß]+)\s*(\d{4})', ts)
        if m:
            g1, a1, g2, a2, yil = m.groups()
            if not a1: a1 = a2
            if is_end: return f"{yil}-{aylar.get(a2,'12')}-{str(g2).zfill(2)}T23:59:59Z"
            else: return f"{yil}-{aylar.get(a1,'01')}-{str(g1).zfill(2)}T00:00:00Z"
    except: return None

def get_category(title, text):
    t = tr_lower(title + " " + text)
    if any(x in t for x in ["market", "bakkal", "s√ºpermarket", "migros"]): return "Market"
    if any(x in t for x in ["restoran", "kafe", "yemek", "burger"]): return "Restoran & Kafe"
    if any(x in t for x in ["akaryakƒ±t", "benzin", "otogaz", "opet", "shell"]): return "Yakƒ±t"
    if any(x in t for x in ["giyim", "moda", "ayakkabƒ±"]): return "Giyim & Moda"
    if any(x in t for x in ["elektronik", "teknoloji", "telefon"]): return "Elektronik"
    if any(x in t for x in ["seyahat", "otel", "u√ßak", "tatil"]): return "Seyahat"
    if any(x in t for x in ["e-ticaret", "online", "internet", "trendyol"]): return "Online Alƒ±≈üveri≈ü"
    return "Diƒüer"

def extract_merchant(title):
    try:
        match = re.search(r"(.+?)['‚Äô](?:ta|te|tan|ten|da|de|dan|den)\s", title, re.IGNORECASE)
        if match:
            merchant = match.group(1).strip()
            if len(merchant.split()) < 5: return merchant
    except: pass
    return None

def extract_cards_refined(text):
    known_cards = [
        "Maximum Gen√ß", "ƒ∞≈ü'te √úniversiteli", "Maximiles", 
        "MercedesCard", "Maximum Pati Kart", "Maximum TEMA Kart", 
        "Maximum Gold", "Maximum Platinum", "Maximum Premier",
        "Privia", "Ticari Kart", "Bankamatik Kartƒ±", "MaxiPara", 
        "Aidatsƒ±z Kart", "Sanal Kart"
    ]
    found = []
    t_low = text.replace('ƒ∞', 'i').lower()
    for card in known_cards:
        if card.lower().replace('i', 'ƒ±') in t_low or card.replace('ƒ∞', 'i').lower() in t_low:
            found.append(card)
    if not found: found = ["Maximum Kart"]
    return list(set(found))

# --- üî• Fƒ∞NANSAL MOTOR V7 (HATASIZ) ---
def extract_financials_v7(text, title):
    text_clean = re.sub(r'(?<=\d)\.(?=\d)', '', text)
    t_low = text_clean.replace('ƒ∞', 'i').lower()
    title_low = title.replace('ƒ∞', 'i').lower()
    
    min_s = 0; max_d = 0; earn = None; disc = None
    
    # 1. Taksit (√ñncelik Ba≈ülƒ±k)
    title_taksit = re.search(r'(\d+)\s*(?:aya varan)?\s*taksit', title_low)
    if title_taksit and int(title_taksit.group(1)) < 20:
        disc = f"{title_taksit.group(1)} Taksit"
    elif "taksit" in t_low:
        # Pe≈üin fiyatƒ±na √∂ncelik
        pesin_m = re.findall(r'pe≈üin fiyatƒ±na\s*(\d+)\s*taksit', t_low)
        if pesin_m:
             disc = f"{max(map(int, pesin_m))} Taksit"
        else:
            taksit_m = re.findall(r'(\d+)\s*(?:aya varan|ay)?\s*taksit', t_low)
            valid_t = [int(t) for t in taksit_m if 2 <= int(t) <= 18]
            if valid_t: disc = f"{max(valid_t)} Taksit"
    
    # Taksit i√ßin aralƒ±k kontrol√º (ID 7 D√ºzeltmesi)
    # "5.000 - 500.000 TL arasƒ±" -> 5.000 alƒ±nmalƒ±
    if disc:
        range_match = re.search(r'(\d+)\s*(?:-|ile)\s*(\d+)\s*tl.*?taksit', t_low)
        if range_match:
             min_s = int(range_match.group(1))
        else:
            s_match = re.search(r'(\d+)\s*tl.*?taksit', t_low)
            if s_match: min_s = int(s_match.group(1))

    # 2. Fiyat Avantajƒ± (ID 91 D√ºzeltmesi)
    price_match = re.search(r'(\d+)\s*tl\s*yerine\s*(\d+)\s*tl', t_low)
    if price_match:
        old = int(price_match.group(1)); new = int(price_match.group(2))
        gain = old - new
        if gain > 0:
            max_d = gain
            earn = f"{format_rakam(gain)} TL ƒ∞ndirim"
            min_s = new
            
    # 3. Y√ºzdesel ƒ∞ndirim (ID 15 D√ºzeltmesi)
    if not earn:
        # Toplam y√ºzdeyi ara (√∂rn: toplamda %25)
        total_perc = re.search(r'toplam(?:da)?\s*%(\d+)', t_low)
        if total_perc:
            rate = int(total_perc.group(1))
            earn = f"%{rate} ƒ∞ndirim"
        else:
            perc_match = re.search(r'%(\d+)', t_low)
            if perc_match:
                rate = int(perc_match.group(1))
                cap_match = re.search(r'(?:en fazla|maksimum|max)\s*(\d+)\s*tl', t_low)
                if cap_match:
                    cap = int(cap_match.group(1))
                    max_d = cap
                    min_s = int(cap * 100 / rate)
                    earn = f"{format_rakam(cap)} TL ƒ∞ndirim"
                else:
                    earn = f"%{rate} ƒ∞ndirim"
                    entry = re.search(r'(\d+)\s*tl.*?alƒ±≈üveri≈ü', t_low)
                    if entry: min_s = int(entry.group(1))

    # 4. Kademeli √ñd√ºl (ID 18 D√ºzeltmesi - E≈üle≈ütirme)
    tier_pattern = r'(\d+)\s*tl.*?(\d+)\s*tl\s*(?:maxipuan|puan|indirim)'
    tiers = re.findall(tier_pattern, t_low)
    
    best_earn = 0; best_spend = 0
    for s_str, e_str in tiers:
        s = int(s_str); e = int(e_str)
        # Harcama √∂d√ºl'den b√ºy√ºk olmalƒ±
        if s > e and e > best_earn:
            best_earn = e; best_spend = s
            
    if best_earn > 0 and (max_d == 0 or best_earn > max_d):
        max_d = best_earn
        min_s = best_spend
        suffix = "ƒ∞ndirim" if "indirim" in title_low else "MaxiPuan"
        earn = f"{format_rakam(best_earn)} TL {suffix}"

    # 5. D√∂ng√ºsel (ID 6 D√ºzeltmesi)
    # "her ... ve √ºzeri ... toplam ... puan"
    unit_match = re.search(r'her\s*(\d+)\s*tl', t_low)
    total_match = re.search(r'toplam(?:da)?\s*(\d+)\s*tl', t_low)
    
    if unit_match and total_match:
        u_spend = int(unit_match.group(1))
        total_cap = int(total_match.group(1))
        
        # Metinde birim kazan√ß (250 TL gibi) ge√ßiyor mu?
        u_earn_match = re.search(r'(\d+)\s*tl\s*(?:maxipuan|puan)', t_low)
        u_earn = int(u_earn_match.group(1)) if u_earn_match else 0
        
        if u_earn > 0 and u_earn < total_cap:
             count = total_cap / u_earn
             calc_spend = int(count * u_spend)
             if total_cap >= max_d:
                 max_d = total_cap
                 min_s = calc_spend
                 suffix = "ƒ∞ndirim" if "indirim" in title_low else "MaxiPuan"
                 earn = f"{format_rakam(total_cap)} TL {suffix}"

    return min_s, earn, disc, max_d

def extract_participation(text):
    methods = []
    t_low = tr_lower(text)
    if "i≈ücep" in t_low or "maximum mobil" in t_low: methods.append("Maximum Mobil / ƒ∞≈üCep")
    sms_match = re.search(r'([a-z0-9]+)\s*yazƒ±p\s*(\d{4})', t_low)
    if sms_match: methods.append(f"SMS ({sms_match.group(1).upper()} -> {sms_match.group(2)})")
    if "otomatik" in t_low and not methods: return "Otomatik Katƒ±lƒ±m"
    return ", ".join(list(set(methods))) if methods else "Detaylarƒ± ƒ∞nceleyin"

# --- ANA AKI≈û ---
def main():
    print(f"üöÄ Maximum Kart - FINAL V7 (Off-Screen)...")
    
    driver = None
    try:
        options = uc.ChromeOptions()
        options.add_argument("--no-first-run")
        options.add_argument("--password-store=basic")
        options.add_argument('--ignore-certificate-errors')
        options.add_argument("--window-position=-10000,0") 
        
        driver = uc.Chrome(options=options, use_subprocess=True)
        driver.get(CAMPAIGNS_URL)
        print("   -> Liste y√ºkleniyor...")
        time.sleep(5)
        
        while True:
            try:
                btn = driver.find_element(By.XPATH, "//button[contains(text(), 'Daha Fazla')]")
                driver.execute_script("arguments[0].scrollIntoView(true);", btn)
                time.sleep(1)
                driver.execute_script("arguments[0].click();", btn)
                time.sleep(2.5)
            except:
                print("      T√ºm liste y√ºklendi.")
                break
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        all_links = []
        for a in soup.find_all('a', href=True):
            if "/kampanyalar/" in a['href'] and "arsiv" not in a['href'] and len(a['href']) > 25:
                all_links.append(urljoin(BASE_URL, a['href']))
        
        unique_links = list(set(all_links))
        print(f"   -> Toplam {len(unique_links)} kampanya bulundu. Filtreleme ve ƒ∞≈üleme ba≈ülƒ±yor...")

        final_data = []
        count = 0
        
        for i, url in enumerate(unique_links, 1):
            if count >= CAMPAIGN_LIMIT: break
            
            try:
                time.sleep(random.uniform(1, 2))
                driver.get(url)
                try: WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "span[id$='CampaignDescription']")))
                except: pass

                d_soup = BeautifulSoup(driver.page_source, 'html.parser')
                title_el = d_soup.select_one('h1.gradient-title-text') or d_soup.find('h1')
                title = temizle_metin(title_el.text) if title_el else "Ba≈ülƒ±k Yok"
                
                # √á√∂p Sayfa Filtresi
                if "ge√ßmi≈ü" in title.lower() or "kampanyalarƒ±" in title.lower() and len(title) < 25:
                    print(f"      [ATLANDI - √á√ñP] {title}")
                    continue

                date_el = d_soup.select_one("span[id$='KampanyaTarihleri']")
                date_text = temizle_metin(date_el.text) if date_el else ""
                
                # Tarih Kontrol√º (Eski kampanyalarƒ± atla)
                vu = format_tarih_iso(date_text, True)
                if vu:
                    vu_date = datetime.strptime(vu, "%Y-%m-%dT%H:%M:%SZ")
                    if vu_date < datetime.now():
                        print(f"      [ATLANDI - S√úRESƒ∞ DOLMU≈û] {title}")
                        continue

                desc_el = d_soup.select_one("span[id$='CampaignDescription']")
                conditions = []
                full_text = ""
                if desc_el:
                    for br in desc_el.find_all("br"): br.replace_with("\n")
                    for p in desc_el.find_all("p"): p.insert(0, "\n")
                    raw_text = desc_el.get_text()
                    conditions = [temizle_metin(line) for line in raw_text.split('\n') if len(temizle_metin(line)) > 15]
                    full_text = " ".join(conditions)
                else:
                    full_text = temizle_metin(d_soup.get_text())
                    conditions = [t for t in full_text.split('\n') if len(t)>20]

                img_el = d_soup.select_one("img[id$='CampaignImage']")
                image = urljoin(BASE_URL, img_el['src']) if img_el else None

                # V7 ANALƒ∞Z
                cat = get_category(title, full_text)
                merchant = extract_merchant(title)
                min_s, earn, disc, max_d = extract_financials_v7(full_text, title)
                cards = extract_cards_refined(full_text)
                vf = format_tarih_iso(date_text, False)
                part_method = extract_participation(full_text)
                
                # Veri Yoksa Bo≈ü Ge√ßme (Fallback)
                if min_s == 0 and earn is None and disc is None:
                     # Ba≈ülƒ±ktan tekrar dene
                     min_s, earn, disc, max_d = extract_financials_v7(title, title)

                count += 1
                print(f"      [{count}] ƒ∞≈ülendi: {title[:40]}...")

                item = {
                    "id": count,
                    "title": title,
                    "provider": IMPORT_SOURCE_NAME,
                    "category": cat,
                    "merchant": merchant,
                    "image": image,
                    "images": [image] if image else [],
                    "description": conditions[0] if conditions else title,
                    "url": url,
                    "discount": disc,
                    "earning": earn,
                    "min_spend": min_s,
                    "max_discount": max_d,
                    "discount_percentage": None,
                    "created_at": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "valid_from": vf,
                    "valid_until": vu,
                    "participation_method": part_method,
                    "conditions": conditions,
                    "eligible_customers": cards,
                    "source_url": BASE_URL
                }
                final_data.append(item)

            except Exception as e:
                print(f"      ‚ö†Ô∏è Hata: {e}")
                continue
        
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=4)
            
        print(f"\n‚úÖ B√úY√úK Fƒ∞NAL TAMAMLANDI! {len(final_data)} kampanya '{OUTPUT_FILE}' dosyasƒ±na kaydedildi.")

    except Exception as main_e:
        print(f"‚ùå Kritik Hata: {main_e}")
    finally:
        if driver: 
            try: driver.quit()
            except: pass

if __name__ == "__main__":
    main()