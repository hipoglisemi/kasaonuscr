import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time
import json
import os
import re
from datetime import datetime
import random
import math

# --- 1. AYARLAR (V13 - Matematiksel DÃ¼zeltme) ---
BASE_URL = "https://www.bonus.com.tr"
CAMPAIGN_LIST_URL = "https://www.bonus.com.tr/kampanyalar"
JSON_FILE_NAME = "bonus_kampanyalar_v13_fixed.json"
IMPORT_SOURCE_NAME = "Bonus (Garanti BBVA)"
CAMPAIGN_LIMIT = 999 

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
    'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7',
    'Cache-Control': 'no-cache',
    'Pragma': 'no-cache'
}

# --- 2. YARDIMCI FONKSÄ°YONLAR ---

def temizle_metin(text):
    if not text: return ""
    try:
        text = re.sub(r'[^\x20-\x7E\u00A0-\uFFFF]', ' ', str(text))
        return re.sub(r'\s+', ' ', text).strip()
    except: return ""

def format_rakam(rakam_int):
    if rakam_int is None: return None
    try: return f"{int(rakam_int):,}".replace(",", ".")
    except: return None

def format_tarih_iso_v25(tarih_str, is_end_date=False):
    if not tarih_str: return None, None
    tarih_str = re.sub(r"['â€™`Â´](?:e|a|ye|ya|'de|'da|â€™de|â€™da)", "", tarih_str.lower().strip())
    aylar = {'ocak': '01', 'ÅŸubat': '02', 'mart': '03', 'nisan': '04', 'mayÄ±s': '05', 'haziran': '06',
             'temmuz': '07', 'aÄŸustos': '08', 'eylÃ¼l': '09', 'ekim': '10', 'kasÄ±m': '11', 'aralÄ±k': '12'}
    
    try:
        parcalar = re.split(r'\s+', tarih_str)
        if len(parcalar) < 2: return None, None
        
        gun_str = ''.join(filter(str.isdigit, parcalar[0])).zfill(2)
        ay_adi = next((m for m in aylar if m in tarih_str), None)
        if not ay_adi: return None, None
        ay_num = aylar[ay_adi]
        
        yil_str = str(datetime.now().year)
        for p in parcalar:
            if p.isdigit() and len(p) == 4:
                yil_str = p
                break
                
        if is_end_date:
            iso_str = f"{yil_str}-{ay_num}-{gun_str}T23:59:59Z"
        else:
            iso_str = f"{yil_str}-{ay_num}-{gun_str}T00:00:00Z"
            
        return iso_str
    except: return None

def tahmin_et_kategori(text):
    text = text.lower()
    if re.search(r'akaryakÄ±t|benzin|shell|opet|bp|petrol ofisi|total|aytemiz', text): return 'YakÄ±t'
    if re.search(r'market|migros|carrefour|a101|ÅŸok|bim|gÄ±da|alÄ±ÅŸveriÅŸ', text): return 'Market'
    if re.search(r'restoran|yemek|cafe|burger|pizza|starbucks|yeme-iÃ§me', text): return 'Restoran & Kafe'
    if re.search(r'elektronik|teknoloji|mediamarkt|teknosa|vatan|beyaz eÅŸya', text): return 'Elektronik'
    if re.search(r'giyim|moda|ayakkabÄ±|lcwaikiki|defacto|beymen|boyner|zara|mavi', text): return 'Giyim & Moda'
    if re.search(r'trendyol|hepsiburada|amazon|n11|pazarama|e-ticaret|internet', text): return 'Online AlÄ±ÅŸveriÅŸ'
    if re.search(r'seyahat|otel|tatil|uÃ§ak|jolly|ets|setur|turizm', text): return 'Seyahat'
    if re.search(r'mtv|vergi|fatura|sgk|eÄŸitim|okul|belediye', text): return 'Kamu & Vergi'
    if re.search(r'mobilya|yatak|ikea|evidea|koÃ§taÅŸ|yapÄ± market', text): return 'Ev & YaÅŸam'
    return 'DiÄŸer'

# --- 3. GELÄ°ÅžMÄ°Åž HESAPLAMA MOTORU (V13) ---

def extract_money(text):
    """Metinden para deÄŸerlerini (TL) Ã§eker, YIL bilgilerini (2025 vb.) filtreler."""
    text = text.lower().replace('.', '').replace(',', '.')
    # YÄ±llarÄ± temizle (2023-2029 arasÄ±)
    text = re.sub(r'202[3-9]', ' ', text)
    
    # RakamlarÄ± bul
    # Ã–rn: 1000 tl, 1000tl, 1000
    matches = re.findall(r'(\d+)\s*(?:tl|try)?', text)
    values = []
    for m in matches:
        try:
            val = int(float(m))
            # MantÄ±k filtresi: 10 TL altÄ± (taksit sayÄ±sÄ± olabilir) ve 5 Milyon TL Ã¼stÃ¼ hariÃ§
            if 10 < val < 5000000: 
                values.append(val)
        except: pass
    return values

def calculate_financials_v13(title, desc, full_text):
    """
    V13 Hesaplama MantÄ±ÄŸÄ±:
    1. Ã–nce Maksimum KazancÄ± (Max Bonus) kesinleÅŸtir.
    2. Bu kazanca ulaÅŸmak iÃ§in gereken harcamayÄ± (Target Spend) bul.
    """
    
    combined_text = f"{title} {desc} {full_text}".lower()
    # Temizlik: NoktalarÄ± binlik ayracÄ± olarak kaldÄ±r, yÄ±llarÄ± sil
    clean_text = combined_text.replace('.', '').replace(',', '.')
    clean_text = re.sub(r'202[3-9]', '', clean_text) # YÄ±llarÄ± uÃ§ur (2025 -> '')

    min_spend = 0
    max_earn = 0
    earning_str = None
    discount_str = None
    discount_perc = None

    # --- A. MAX KAZANÃ‡ TESPÄ°TÄ° ---
    # "Toplamda 500 TL", "En fazla 1.000 TL", "1.500 TL bonus"
    # Ã–nce "toplam/en fazla" ifadelerine bak
    potential_max_rewards = []
    
    # Regex 1: "toplam/en fazla ... X TL ... bonus/puan/indirim"
    matches_max = re.findall(r'(?:toplam|en fazla|maksimum|kazanabileceÄŸiniz)\s*.*?(\d+)\s*(?:tl)?\s*(?:bonus|puan|indirim)', clean_text)
    for m in matches_max:
        try: potential_max_rewards.append(int(m))
        except: pass

    # Regex 2: BaÅŸlÄ±ktaki net bonus ifadesi (Ã–rn: "1.000 TL Bonus")
    title_clean = title.lower().replace('.', '').replace(',', '.')
    matches_title = re.findall(r'(\d+)\s*(?:tl)?\s*bonus', title_clean)
    for m in matches_title:
        try: potential_max_rewards.append(int(m))
        except: pass
        
    if potential_max_rewards:
        max_earn = max(potential_max_rewards)
    
    # EÄŸer hala 0 ise description'dan bulmaya Ã§alÄ±ÅŸ
    if max_earn == 0:
        desc_clean = desc.lower().replace('.', '').replace(',', '.')
        matches_desc = re.findall(r'(\d+)\s*(?:tl)?\s*bonus', desc_clean)
        if matches_desc:
             max_earn = max([int(x) for x in matches_desc])

    # --- B. HARCAMA (TARGET SPEND) TESPÄ°TÄ° ---
    
    spend_found = False

    # Senaryo 1: Kademeli (Tiered) - "50.000 TL'ye 1.200 TL Bonus"
    # En yÃ¼ksek Ã¶dÃ¼lÃ¼ veren harcamayÄ± bulmaya Ã§alÄ±ÅŸÄ±rÄ±z.
    if max_earn > 0:
        # (Harcama) ... (Ã–dÃ¼l) ikililerini bul
        # Ã–rn: "10000 tl ... 500 tl bonus"
        tiers = re.findall(r'(\d+)\s*tl.*?(\d+)\s*tl\s*(?:bonus|puan|indirim)', clean_text)
        best_spend_for_max = 0
        
        for s_str, e_str in tiers:
            spend = int(s_str)
            earn = int(e_str)
            # EÄŸer bu kademenin Ã¶dÃ¼lÃ¼, bulduÄŸumuz Max Ã¶dÃ¼le eÅŸit veya Ã§ok yakÄ±nsa
            if earn >= max_earn * 0.9: 
                if spend > best_spend_for_max:
                    best_spend_for_max = spend
        
        if best_spend_for_max > 0:
            min_spend = best_spend_for_max
            spend_found = True

    # Senaryo 2: DÃ¶ngÃ¼sel (Recurring) - "Her 2.500 TL'ye 130 TL"
    # Bu senaryoda Max Ã–dÃ¼l'e ulaÅŸmak iÃ§in kaÃ§ tur gerektiÄŸini hesaplarÄ±z.
    if not spend_found and "her" in clean_text and max_earn > 0:
        # "her ... X TL ... Y TL bonus"
        cycle_matches = re.findall(r'her\s*(\d+)\s*tl.*?(\d+)\s*tl\s*(?:bonus|puan)', clean_text)
        for s_str, e_str in cycle_matches:
            spend_unit = int(s_str)
            earn_unit = int(e_str)
            
            if earn_unit > 0:
                required_steps = math.ceil(max_earn / earn_unit)
                calculated_spend = required_steps * spend_unit
                # MantÄ±k kontrolÃ¼: Harcama bonusun en az 2 katÄ± olmalÄ± (genelde %50'den fazla bonus vermezler)
                if calculated_spend >= max_earn * 2:
                    min_spend = calculated_spend
                    spend_found = True
                    break

    # Senaryo 3: YÃ¼zde (%) - "%10 Bonus... En fazla 500 TL"
    if not spend_found and max_earn > 0:
        perc_match = re.search(r'%\s*(\d+)', clean_text)
        if perc_match:
            rate = int(perc_match.group(1))
            discount_perc = rate
            discount_str = f"%{rate}"
            if rate > 0:
                # 500 / 0.10 = 5000
                calculated_spend = int(max_earn / (rate / 100))
                min_spend = calculated_spend
                spend_found = True

    # Senaryo 4: DÃ¼z GiriÅŸ Limiti (Fallback) - "1.000 TL ve Ã¼zeri"
    # EÄŸer yukarÄ±dakiler Ã§alÄ±ÅŸmadÄ±ysa, metindeki en bÃ¼yÃ¼k mantÄ±klÄ± harcama tutarÄ±nÄ± al
    if not spend_found:
        # "X TL ve Ã¼zeri" geÃ§en sayÄ±larÄ± al
        limits = re.findall(r'(\d+)\s*tl.*?Ã¼zeri', clean_text)
        valid_limits = []
        for l in limits:
            val = int(l)
            # YÄ±l (2025) ile karÄ±ÅŸmamasÄ± iÃ§in kontrol, zaten text clean'de sildik ama 
            # 2000-2030 aralÄ±ÄŸÄ±na dikkat. Genelde harcama limitleri yuvarlaktÄ±r.
            if val > 50: 
                valid_limits.append(val)
        
        if valid_limits:
            if max_earn > 500: 
                # EÄŸer Ã¶dÃ¼l bÃ¼yÃ¼kse, muhtemelen en yÃ¼ksek limiti istiyorlardÄ±r
                min_spend = max(valid_limits)
            else:
                # Ã–dÃ¼l kÃ¼Ã§Ã¼kse, giriÅŸ limitini al
                min_spend = min(valid_limits)

    # String Formatlama
    if max_earn > 0:
        earning_str = f"{format_rakam(max_earn)} TL Bonus"
    elif discount_str:
        earning_str = f"{discount_str} Ä°ndirim"
    else:
        taksit_match = re.search(r'(\d+)\s*taksit', clean_text)
        if taksit_match:
            earning_str = f"{taksit_match.group(1)} Taksit"
            discount_str = f"{taksit_match.group(1)} Taksit"

    return min_spend, earning_str, discount_str, discount_perc, max_earn

# --- 4. DÄ°ÄžER AYRIÅžTIRICILAR ---

def extract_cards_final(soup):
    full_text = soup.get_text()
    card_patterns = [
        (r'bonus\s+genÃ§', "Bonus GenÃ§"),
        (r'bonus\s+flexi', "Bonus Flexi"),
        (r'money\s+bonus', "Money Bonus"),
        (r'bonus\s+business', "Bonus Business"),
        (r'miles', "Miles&Smiles Garanti BBVA"),
        (r'shop', "Shop&Fly"),
        (r'american', "American Express"),
        (r'paracard', "Paracard"),
        (r'flexi', "Flexi"),
        (r'easy', "Easy"),
        (r'troy', "Troy Logolu Kartlar"),
        (r'bonus\s+platinum', "Bonus Platinum"),
        (r'bonus\s+gold', "Bonus Gold"),
        (r'garanti\s+bonus', "Garanti Bonus")
    ]
    
    found_cards = []
    text_lower = full_text.lower()
    # "Dahil deÄŸildir" kÄ±smÄ±nÄ± atÄ±p pozitif metinde ara
    text_positive = re.split(r'dahil\s+deÄŸil', text_lower)[0]
    
    for pattern, name in card_patterns:
        if re.search(pattern, text_positive):
            if name not in found_cards:
                found_cards.append(name)
    
    if not found_cards:
        found_cards = ["Garanti Bonus"]
    return found_cards

def extract_participation_final(soup):
    method = "DetaylarÄ± kontrol ediniz."
    points = []
    text = soup.get_text()
    
    sms_match = re.search(r'([A-ZÄ°Ã–ÃœÅžÄžÃ‡0-9]{3,15})\s*(?:yazÄ±p|yaz)\s*,?\s*(?:3340)', text, re.IGNORECASE)
    sms_text = ""
    if sms_match:
        keyword = sms_match.group(1).upper().strip()
        if keyword not in ["BONUS", "HEMEN", "KAMPANYA"]:
            sms_text = f"SMS ({keyword} -> 3340)"
            points.append(f"{keyword} yazÄ±p 3340'a SMS gÃ¶nderiniz.")
            
    has_app = "BonusFlaÅŸ" in text or "Hemen KatÄ±l" in text
    
    if has_app and sms_text:
        method = f"BonusFlaÅŸ veya {sms_text}"
        points.insert(0, "BonusFlaÅŸ uygulamasÄ±ndan 'Hemen KatÄ±l' butonuna tÄ±klayÄ±nÄ±z.")
    elif has_app:
        method = "BonusFlaÅŸ UygulamasÄ±"
        points.append("BonusFlaÅŸ uygulamasÄ±ndan 'Hemen KatÄ±l' butonuna tÄ±klayÄ±nÄ±z.")
    elif sms_text:
        method = sms_text
        
    if "otomatik" in text.lower() and not sms_text and not has_app:
        method = "Otomatik KatÄ±lÄ±m"
        points = ["Kampanyaya katÄ±lÄ±m otomatiktir."]
        
    return method, points

# --- 5. ANA PARSER ---

def parse_campaign_v13(soup, url, c_id):
    title_elm = soup.select_one('.campaign-detail-title h1')
    title = temizle_metin(title_elm.get_text()) if title_elm else "BaÅŸlÄ±k BulunamadÄ±"
    
    img_elm = soup.select_one('.campaign-detail__image img')
    image_url = urljoin(BASE_URL, img_elm['src']) if img_elm else None
    
    date_elm = soup.select_one('.campaign-date')
    date_text = temizle_metin(date_elm.get_text()) if date_elm else ""
    
    # Tarih
    parts = date_text.split('-')
    valid_from = None
    valid_until = None
    if len(parts) > 0:
        valid_from = format_tarih_iso_v25(parts[0].strip(), is_end_date=False)
    if len(parts) > 1:
        valid_until = format_tarih_iso_v25(parts[-1].strip(), is_end_date=True)
    elif len(parts) == 1 and valid_from:
        valid_until = format_tarih_iso_v25(parts[0].strip(), is_end_date=True)
        valid_from = None 

    desc = title
    how_win_header = soup.find('h2', string=re.compile('NASIL KAZANIRIM', re.IGNORECASE))
    if how_win_header:
        desc_p = how_win_header.find_next_sibling('p')
        if desc_p: desc = temizle_metin(desc_p.get_text())

    # Metni birleÅŸtir (BaÅŸlÄ±k + AÃ§Ä±klama + Detaylar)
    full_text_raw = soup.get_text(separator=' ')
    
    # --- HESAPLAMA MOTORUNU Ã‡ALIÅžTIR ---
    min_spend, earning, discount, discount_perc, max_earn = calculate_financials_v13(title, desc, full_text_raw)
    
    eligible_cards = extract_cards_final(soup)
    part_method, part_points = extract_participation_final(soup)
    
    conditions = []
    detail_list = soup.select('.how-to-win ul.disc li')
    for li in detail_list:
        txt = temizle_metin(li.get_text())
        if txt and len(txt) > 15:
            conditions.append(txt)

    category = tahmin_et_kategori(title + " " + desc)
    
    difficulty = "Kolay"
    if "SMS" in part_method or "BonusFlaÅŸ" in part_method: difficulty = "Orta"
    if min_spend > 5000: difficulty = "Zor"

    return {
        "id": c_id,
        "title": title,
        "description": desc,
        "provider": IMPORT_SOURCE_NAME,
        "category": category,
        "url": url,
        "image": image_url,
        "images": [image_url] if image_url else [],
        "discount": discount,
        "earning": earning,
        "min_spend": min_spend,
        "max_discount": max_earn,
        "discount_percentage": discount_perc,
        "valid_from": valid_from,
        "valid_until": valid_until,
        "participation_method": part_method,
        "participation_points": part_points,
        "conditions": conditions[:30],
        "eligible_customers": eligible_cards,
        "difficulty_level": difficulty,
        "created_at": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ"),
        "source_url": BASE_URL
    }

def get_campaign_list(session):
    print("Kampanya linkleri taranÄ±yor...")
    links = []
    try:
        resp = session.get(CAMPAIGN_LIST_URL, headers=HEADERS, timeout=20)
        soup = BeautifulSoup(resp.content, 'html.parser')
        for a in soup.find_all('a', href=True):
            href = a['href']
            if '/kampanyalar/' in href and len(href.split('/')) > 2:
                if not any(x in href for x in ['sektor', 'kategori', 'marka', '#', 'javascript']):
                    full = urljoin(BASE_URL, href)
                    if full not in links: links.append(full)
    except Exception as e:
        print(f"Liste hatasÄ±: {e}")
    return links

if __name__ == "__main__":
    print(f"Garanti Bonus Scraper V13 (Fixed Math Logic) BaÅŸlatÄ±lÄ±yor...")
    all_data = []
    with requests.Session() as s:
        urls = get_campaign_list(s)
        if len(urls) > CAMPAIGN_LIMIT: urls = urls[:CAMPAIGN_LIMIT]
        
        print(f"Toplam {len(urls)} kampanya iÅŸlenecek...")
        for i, url in enumerate(urls, 1):
            print(f"[{i}/{len(urls)}] Ä°ÅŸleniyor: {url}")
            try:
                resp = s.get(url, headers=HEADERS, timeout=15)
                soup = BeautifulSoup(resp.content, 'html.parser')
                data = parse_campaign_v13(soup, url, i)
                if data: 
                    all_data.append(data)
                    # Kontrol Ã‡Ä±ktÄ±sÄ±
                    print(f"   -> Spend: {data['min_spend']}, Max Earn: {data['max_discount']}")
            except Exception as e:
                print(f"Hata: {e}")
            time.sleep(random.uniform(0.5, 1.2))
            
    if all_data:
        with open(JSON_FILE_NAME, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=4)
        print(f"ðŸŽ‰ Ä°ÅŸlem TamamlandÄ±: {JSON_FILE_NAME}")
